# CIFAR10 + RESNET20 with this config

pruners:
  pruner_1:
    class: UnstructuredMagnitudePruner
    epochs: [10, 40, 171]
    initial_sparsity: 0.9
    target_sparsity: 0.9
    weight_only: True
    modules: [conv1, layer1.0.conv1, layer1.0.conv2,
              layer1.1.conv1, layer1.1.conv2,
              layer1.2.conv1, layer1.2.conv2,
              layer2.0.conv1, layer2.0.conv2,
              layer2.1.conv1, layer2.1.conv2,
              layer2.2.conv1, layer2.2.conv2,
              layer3.0.conv1, layer3.0.conv2,
              layer3.1.conv1, layer3.1.conv2,
              layer3.2.conv1, layer3.2.conv2, fc]
    keep_pruned: False

recyclers:
  recycler_1:
    class: RestoreWeights
    weight_only: True
    epochs: [30, 40, 151] # [start, freq, end] for now (TODO: but can extend functionality?)
    modules: [conv1, layer1.0.conv1, layer1.0.conv2,
              layer1.1.conv1, layer1.1.conv2,
              layer1.2.conv1, layer1.2.conv2,
              layer2.0.conv1, layer2.0.conv2,
              layer2.1.conv1, layer2.1.conv2,
              layer2.2.conv1, layer2.2.conv2,
              layer3.0.conv1, layer3.0.conv2,
              layer3.1.conv1, layer3.1.conv2,
              layer3.2.conv1, layer3.2.conv2, fc]

trainers:
  # use this trainer name unless you want KD or other custom thing
  default_trainer:
    optimizer:
      class: SGD    
      lr: 0.1
      momentum: 0.9
      weight_decay: 0.0005

    lr_scheduler:
      class: ExponentialLR
      gamma: 0.1
      epochs: [65, 60, 200]

